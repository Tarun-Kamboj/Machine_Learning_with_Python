# Support-Vector Machines (SVMs)

![](http://ForTheBadge.com/images/badges/made-with-python.svg) 

## Dependencies

![](https://img.shields.io/badge/pandas-1.2.3-150458?style=for-the-badge&logo=pandas)
![](https://img.shields.io/badge/numpy-1.19.2-013243?style=for-the-badge&logo=NumPy)
![](https://img.shields.io/badge/matplotlib-3.3.4-224099?style=for-the-badge)
![](https://img.shields.io/badge/scikit_learn-0.24.1-F7931E?style=for-the-badge&logo=scikit-learn)
![](https://img.shields.io/badge/itertools-8.7.0-134567?style=for-the-badge)

## Introduction

In machine learning, `support-vector machines` (SVMs) are supervised learning models with associated learning algorithms that analyze data for classification and regression analysis.

SVMs are one of the most robust prediction methods, being based on statistical learning frameworks. Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier. An SVM maps training examples to points in space so as to maximise the width of the gap between the two categories. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall.

In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.

In the [Notebook](Notebook.ipynb), we learn how to use scikit-learn to implement SVMs. 

## Thanks for Reading :)